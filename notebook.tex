
% Default to the notebook output style

    


% Inherit from the specified cell style.




    
\documentclass[11pt]{article}

    
    
    \usepackage[T1]{fontenc}
    % Nicer default font (+ math font) than Computer Modern for most use cases
    \usepackage{mathpazo}

    % Basic figure setup, for now with no caption control since it's done
    % automatically by Pandoc (which extracts ![](path) syntax from Markdown).
    \usepackage{graphicx}
    % We will generate all images so they have a width \maxwidth. This means
    % that they will get their normal width if they fit onto the page, but
    % are scaled down if they would overflow the margins.
    \makeatletter
    \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth
    \else\Gin@nat@width\fi}
    \makeatother
    \let\Oldincludegraphics\includegraphics
    % Set max figure width to be 80% of text width, for now hardcoded.
    \renewcommand{\includegraphics}[1]{\Oldincludegraphics[width=.8\maxwidth]{#1}}
    % Ensure that by default, figures have no caption (until we provide a
    % proper Figure object with a Caption API and a way to capture that
    % in the conversion process - todo).
    \usepackage{caption}
    \DeclareCaptionLabelFormat{nolabel}{}
    \captionsetup{labelformat=nolabel}

    \usepackage{adjustbox} % Used to constrain images to a maximum size 
    \usepackage{xcolor} % Allow colors to be defined
    \usepackage{enumerate} % Needed for markdown enumerations to work
    \usepackage{geometry} % Used to adjust the document margins
    \usepackage{amsmath} % Equations
    \usepackage{amssymb} % Equations
    \usepackage{textcomp} % defines textquotesingle
    % Hack from http://tex.stackexchange.com/a/47451/13684:
    \AtBeginDocument{%
        \def\PYZsq{\textquotesingle}% Upright quotes in Pygmentized code
    }
    \usepackage{upquote} % Upright quotes for verbatim code
    \usepackage{eurosym} % defines \euro
    \usepackage[mathletters]{ucs} % Extended unicode (utf-8) support
    \usepackage[utf8x]{inputenc} % Allow utf-8 characters in the tex document
    \usepackage{fancyvrb} % verbatim replacement that allows latex
    \usepackage{grffile} % extends the file name processing of package graphics 
                         % to support a larger range 
    % The hyperref package gives us a pdf with properly built
    % internal navigation ('pdf bookmarks' for the table of contents,
    % internal cross-reference links, web links for URLs, etc.)
    \usepackage{hyperref}
    \usepackage{longtable} % longtable support required by pandoc >1.10
    \usepackage{booktabs}  % table support for pandoc > 1.12.2
    \usepackage[inline]{enumitem} % IRkernel/repr support (it uses the enumerate* environment)
    \usepackage[normalem]{ulem} % ulem is needed to support strikethroughs (\sout)
                                % normalem makes italics be italics, not underlines
    

    
    
    % Colors for the hyperref package
    \definecolor{urlcolor}{rgb}{0,.145,.698}
    \definecolor{linkcolor}{rgb}{.71,0.21,0.01}
    \definecolor{citecolor}{rgb}{.12,.54,.11}

    % ANSI colors
    \definecolor{ansi-black}{HTML}{3E424D}
    \definecolor{ansi-black-intense}{HTML}{282C36}
    \definecolor{ansi-red}{HTML}{E75C58}
    \definecolor{ansi-red-intense}{HTML}{B22B31}
    \definecolor{ansi-green}{HTML}{00A250}
    \definecolor{ansi-green-intense}{HTML}{007427}
    \definecolor{ansi-yellow}{HTML}{DDB62B}
    \definecolor{ansi-yellow-intense}{HTML}{B27D12}
    \definecolor{ansi-blue}{HTML}{208FFB}
    \definecolor{ansi-blue-intense}{HTML}{0065CA}
    \definecolor{ansi-magenta}{HTML}{D160C4}
    \definecolor{ansi-magenta-intense}{HTML}{A03196}
    \definecolor{ansi-cyan}{HTML}{60C6C8}
    \definecolor{ansi-cyan-intense}{HTML}{258F8F}
    \definecolor{ansi-white}{HTML}{C5C1B4}
    \definecolor{ansi-white-intense}{HTML}{A1A6B2}

    % commands and environments needed by pandoc snippets
    % extracted from the output of `pandoc -s`
    \providecommand{\tightlist}{%
      \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
    \DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
    % Add ',fontsize=\small' for more characters per line
    \newenvironment{Shaded}{}{}
    \newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.56,0.13,0.00}{{#1}}}
    \newcommand{\DecValTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\FloatTok}[1]{\textcolor[rgb]{0.25,0.63,0.44}{{#1}}}
    \newcommand{\CharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\StringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\CommentTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textit{{#1}}}}
    \newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{{#1}}}
    \newcommand{\AlertTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.02,0.16,0.49}{{#1}}}
    \newcommand{\RegionMarkerTok}[1]{{#1}}
    \newcommand{\ErrorTok}[1]{\textcolor[rgb]{1.00,0.00,0.00}{\textbf{{#1}}}}
    \newcommand{\NormalTok}[1]{{#1}}
    
    % Additional commands for more recent versions of Pandoc
    \newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.53,0.00,0.00}{{#1}}}
    \newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.25,0.44,0.63}{{#1}}}
    \newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.73,0.40,0.53}{{#1}}}
    \newcommand{\ImportTok}[1]{{#1}}
    \newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.73,0.13,0.13}{\textit{{#1}}}}
    \newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\VariableTok}[1]{\textcolor[rgb]{0.10,0.09,0.49}{{#1}}}
    \newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.44,0.13}{\textbf{{#1}}}}
    \newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.40,0.40,0.40}{{#1}}}
    \newcommand{\BuiltInTok}[1]{{#1}}
    \newcommand{\ExtensionTok}[1]{{#1}}
    \newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.74,0.48,0.00}{{#1}}}
    \newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.49,0.56,0.16}{{#1}}}
    \newcommand{\InformationTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    \newcommand{\WarningTok}[1]{\textcolor[rgb]{0.38,0.63,0.69}{\textbf{\textit{{#1}}}}}
    
    
    % Define a nice break command that doesn't care if a line doesn't already
    % exist.
    \def\br{\hspace*{\fill} \\* }
    % Math Jax compatability definitions
    \def\gt{>}
    \def\lt{<}
    % Document parameters
    \title{ysc\_model\_p3}
    
    
    

    % Pygments definitions
    
\makeatletter
\def\PY@reset{\let\PY@it=\relax \let\PY@bf=\relax%
    \let\PY@ul=\relax \let\PY@tc=\relax%
    \let\PY@bc=\relax \let\PY@ff=\relax}
\def\PY@tok#1{\csname PY@tok@#1\endcsname}
\def\PY@toks#1+{\ifx\relax#1\empty\else%
    \PY@tok{#1}\expandafter\PY@toks\fi}
\def\PY@do#1{\PY@bc{\PY@tc{\PY@ul{%
    \PY@it{\PY@bf{\PY@ff{#1}}}}}}}
\def\PY#1#2{\PY@reset\PY@toks#1+\relax+\PY@do{#2}}

\expandafter\def\csname PY@tok@kc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@vg\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PY@tok@ni\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.60,0.60,0.60}{##1}}}
\expandafter\def\csname PY@tok@gh\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@no\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@c\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@s\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kr\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@se\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.13}{##1}}}
\expandafter\def\csname PY@tok@gp\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@kt\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.69,0.00,0.25}{##1}}}
\expandafter\def\csname PY@tok@nv\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@mh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@vc\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@nt\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sx\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cs\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@ow\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@si\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@o\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mo\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@mb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@cp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.74,0.48,0.00}{##1}}}
\expandafter\def\csname PY@tok@nf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@ne\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.82,0.25,0.23}{##1}}}
\expandafter\def\csname PY@tok@kp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@kd\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@vi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gs\endcsname{\let\PY@bf=\textbf}
\expandafter\def\csname PY@tok@m\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@nn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@cm\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nb\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@go\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.53,0.53,0.53}{##1}}}
\expandafter\def\csname PY@tok@nc\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@sh\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@kn\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@gd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@sa\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@nl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.63,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@bp\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@w\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PY@tok@cpf\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@fm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.00,1.00}{##1}}}
\expandafter\def\csname PY@tok@err\endcsname{\def\PY@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PY@tok@ge\endcsname{\let\PY@it=\textit}
\expandafter\def\csname PY@tok@ch\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@vm\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@gu\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PY@tok@il\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@sd\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@dl\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@mf\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PY@tok@s1\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}
\expandafter\def\csname PY@tok@c1\endcsname{\let\PY@it=\textit\def\PY@tc##1{\textcolor[rgb]{0.25,0.50,0.50}{##1}}}
\expandafter\def\csname PY@tok@nd\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.67,0.13,1.00}{##1}}}
\expandafter\def\csname PY@tok@ss\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.10,0.09,0.49}{##1}}}
\expandafter\def\csname PY@tok@k\endcsname{\let\PY@bf=\textbf\def\PY@tc##1{\textcolor[rgb]{0.00,0.50,0.00}{##1}}}
\expandafter\def\csname PY@tok@sr\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.40,0.53}{##1}}}
\expandafter\def\csname PY@tok@gr\endcsname{\def\PY@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PY@tok@na\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.49,0.56,0.16}{##1}}}
\expandafter\def\csname PY@tok@gi\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PY@tok@s2\endcsname{\def\PY@tc##1{\textcolor[rgb]{0.73,0.13,0.13}{##1}}}

\def\PYZbs{\char`\\}
\def\PYZus{\char`\_}
\def\PYZob{\char`\{}
\def\PYZcb{\char`\}}
\def\PYZca{\char`\^}
\def\PYZam{\char`\&}
\def\PYZlt{\char`\<}
\def\PYZgt{\char`\>}
\def\PYZsh{\char`\#}
\def\PYZpc{\char`\%}
\def\PYZdl{\char`\$}
\def\PYZhy{\char`\-}
\def\PYZsq{\char`\'}
\def\PYZdq{\char`\"}
\def\PYZti{\char`\~}
% for compatibility with earlier versions
\def\PYZat{@}
\def\PYZlb{[}
\def\PYZrb{]}
\makeatother


    % Exact colors from NB
    \definecolor{incolor}{rgb}{0.0, 0.0, 0.5}
    \definecolor{outcolor}{rgb}{0.545, 0.0, 0.0}



    
    % Prevent overflowing lines due to hard-to-break entities
    \sloppy 
    % Setup hyperref package
    \hypersetup{
      breaklinks=true,  % so long urls are correctly broken across lines
      colorlinks=true,
      urlcolor=urlcolor,
      linkcolor=linkcolor,
      citecolor=citecolor,
      }
    % Slightly bigger margins than the latex defaults
    
    \geometry{verbose,tmargin=1in,bmargin=1in,lmargin=1in,rmargin=1in}
    
    

    \begin{document}
    
    
    \maketitle
    
    

    
    \section{Behavioral Cloning Model for a Simulated Self-Driving
Car}\label{behavioral-cloning-model-for-a-simulated-self-driving-car}

The goal of this project is to train a model to navigate a vehicle
across a track on it's own. Using Udacity's vehicle simulation, I'll
first manually navigate a vehicle around a track a few times, while
gathering corresponding image + input data. Next, I'll take the
appropriate measures to preprocess the data that will be used to train a
generalized CNN model that will navigate across the track on it's own.

    \subsubsection{Import Dependencies}\label{import-dependencies}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}1}]:} \PY{k+kn}{import} \PY{n+nn}{csv}\PY{o}{,}\PY{n+nn}{cv2}\PY{o}{,}\PY{n+nn}{random}\PY{o}{,}\PY{n+nn}{time}\PY{o}{,}\PY{n+nn}{math}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{layers} \PY{k}{import} \PY{n}{Dense}\PY{p}{,} \PY{n}{Flatten}\PY{p}{,} \PY{n}{Lambda}\PY{p}{,} \PY{n}{Convolution2D}\PY{p}{,} \PY{n}{pooling}\PY{p}{,} \PY{n}{MaxPooling2D}\PY{p}{,} \PY{n}{Cropping2D}\PY{p}{,} \PY{n}{Dropout}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{models} \PY{k}{import} \PY{n}{Sequential}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{optimizers} \PY{k}{import} \PY{n}{Adam}
        \PY{k+kn}{from} \PY{n+nn}{keras}\PY{n+nn}{.}\PY{n+nn}{regularizers} \PY{k}{import} \PY{n}{l2}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{utils} \PY{k}{import} \PY{n}{shuffle}
        \PY{k+kn}{from} \PY{n+nn}{sklearn}\PY{n+nn}{.}\PY{n+nn}{model\PYZus{}selection} \PY{k}{import} \PY{n}{train\PYZus{}test\PYZus{}split}
        \PY{k+kn}{import} \PY{n+nn}{matplotlib}\PY{n+nn}{.}\PY{n+nn}{pyplot} \PY{k}{as} \PY{n+nn}{plt}
        \PY{k+kn}{import} \PY{n+nn}{numpy} \PY{k}{as} \PY{n+nn}{np}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
Using TensorFlow backend.

    \end{Verbatim}

    \subsubsection{Load Driving Data}\label{load-driving-data}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}2}]:} \PY{n}{use\PYZus{}my\PYZus{}data} \PY{o}{=} \PY{k+kc}{True}
            
        \PY{k}{if} \PY{n}{use\PYZus{}my\PYZus{}data}\PY{p}{:}
            \PY{n}{path\PYZus{}split} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+se}{\PYZbs{}\PYZbs{}}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{folder\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./my\PYZus{}track\PYZus{}data/}\PY{l+s+s1}{\PYZsq{}}
        \PY{k}{else}\PY{p}{:}
            \PY{n}{path\PYZus{}split} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{/}\PY{l+s+s1}{\PYZsq{}}
            \PY{n}{folder\PYZus{}path} \PY{o}{=} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{./provided\PYZus{}track\PYZus{}data/}\PY{l+s+s1}{\PYZsq{}}
        
        \PY{n}{log\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}
        \PY{k}{with} \PY{n+nb}{open}\PY{p}{(}\PY{n}{folder\PYZus{}path} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{driving\PYZus{}log.csv}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)} \PY{k}{as} \PY{n}{driving\PYZus{}log}\PY{p}{:}
            \PY{n}{reader} \PY{o}{=} \PY{n}{csv}\PY{o}{.}\PY{n}{reader}\PY{p}{(}\PY{n}{driving\PYZus{}log}\PY{p}{)}
            \PY{k}{for} \PY{n}{line} \PY{o+ow}{in} \PY{n}{reader}\PY{p}{:}
                \PY{n}{log\PYZus{}list}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{line}\PY{p}{)}
        
        \PY{n}{log\PYZus{}list} \PY{o}{=} \PY{n}{log\PYZus{}list}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}
        \PY{n+nb}{len}\PY{p}{(}\PY{n}{log\PYZus{}list}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}2}]:} 18237
\end{Verbatim}
            
    \subsubsection{Define and Display a Test
Image}\label{define-and-display-a-test-image}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}3}]:} \PY{c+c1}{\PYZsh{} retrieve test image from log}
        \PY{n}{test\PYZus{}log} \PY{o}{=} \PY{n}{log\PYZus{}list}\PY{p}{[}\PY{l+m+mi}{42}\PY{p}{]}
        \PY{n}{center\PYZus{}image\PYZus{}path} \PY{o}{=} \PY{n}{folder\PYZus{}path} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IMG/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{test\PYZus{}log}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{path\PYZus{}split}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
        \PY{n}{test\PYZus{}image} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{center\PYZus{}image\PYZus{}path}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}3}]:} <matplotlib.image.AxesImage at 0x2245f1d2cc0>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_6_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Convert BGR Images to
RGB}\label{convert-bgr-images-to-rgb}

Training data is recorded in BGR, while the drive.py file (used to run
the automated simulation of training model) uses RGB. Thus, we need this
conversion function to convert all our images to RGB prior to training.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}4}]:} \PY{k}{def} \PY{n+nf}{bgr\PYZus{}to\PYZus{}rgb}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{img}\PY{p}{,}\PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}BGR2RGB}\PY{p}{)}
        
        \PY{n}{test\PYZus{}image\PYZus{}rgb} \PY{o}{=} \PY{n}{bgr\PYZus{}to\PYZus{}rgb}\PY{p}{(}\PY{n}{test\PYZus{}image}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}rgb}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}4}]:} <matplotlib.image.AxesImage at 0x2245f24d748>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_8_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Crop Top/Bottom Parts of Training
Images}\label{crop-topbottom-parts-of-training-images}

Removing portions of the image helps to focus on whats really important
(the road).

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}5}]:} \PY{k}{def} \PY{n+nf}{crop}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{img}\PY{p}{[}\PY{l+m+mi}{60}\PY{p}{:}\PY{l+m+mi}{135}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{]}
        
        \PY{n}{test\PYZus{}image\PYZus{}crop} \PY{o}{=} \PY{n}{crop}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}rgb}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}crop}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}5}]:} <matplotlib.image.AxesImage at 0x2245f2924a8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_10_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Resize Images Down to
64x64}\label{resize-images-down-to-64x64}

This helps to reduce the memory load and complexity of a training model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}6}]:} \PY{k}{def} \PY{n+nf}{resize}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{resize}\PY{p}{(}\PY{n}{img}\PY{p}{,}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{)}\PY{p}{,} \PY{n}{interpolation} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{INTER\PYZus{}AREA}\PY{p}{)}
        
        \PY{n}{test\PYZus{}image\PYZus{}resize} \PY{o}{=} \PY{n}{resize}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}crop}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}resize}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}6}]:} <matplotlib.image.AxesImage at 0x2245f2c95f8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_12_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Apply Gaussian Blur}\label{apply-gaussian-blur}

Blurring the images helps to generalize the roads better.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}7}]:} \PY{k}{def} \PY{n+nf}{blur}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{c+c1}{\PYZsh{} apply blur}
            \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{GaussianBlur}\PY{p}{(}\PY{n}{img}\PY{p}{,} \PY{p}{(}\PY{l+m+mi}{3}\PY{p}{,}\PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{l+m+mi}{0}\PY{p}{)}
        
        \PY{n}{test\PYZus{}image\PYZus{}blur} \PY{o}{=} \PY{n}{blur}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}resize}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}blur}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}7}]:} <matplotlib.image.AxesImage at 0x2245f307978>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_14_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Apply Random Brightness}\label{apply-random-brightness}

Providing variations on the image brightness (lighter/darker) can also
have a signficant impact on generalizing the model.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}8}]:} \PY{c+c1}{\PYZsh{} brightness isn\PYZsq{}t applied to images until we utilize our data\PYZus{}generator}
        \PY{k}{def} \PY{n+nf}{random\PYZus{}brightness}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{n}{hsv\PYZus{}img} \PY{o}{=} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{img}\PY{p}{,}\PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}RGB2HSV}\PY{p}{)}
            \PY{n}{brightness} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.35}\PY{p}{,}\PY{l+m+mf}{1.0}\PY{p}{)}
            \PY{n}{hsv\PYZus{}img}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]} \PY{o}{=} \PY{n}{hsv\PYZus{}img}\PY{p}{[}\PY{p}{:}\PY{p}{,}\PY{p}{:}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{]}\PY{o}{*}\PY{n}{brightness}
            \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{cvtColor}\PY{p}{(}\PY{n}{hsv\PYZus{}img}\PY{p}{,}\PY{n}{cv2}\PY{o}{.}\PY{n}{COLOR\PYZus{}HSV2RGB}\PY{p}{)}
        
        \PY{n}{test\PYZus{}image\PYZus{}brighten} \PY{o}{=} \PY{n}{random\PYZus{}brightness}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}blur}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}brighten}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}8}]:} <matplotlib.image.AxesImage at 0x2245f34a630>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_16_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Flip Images}\label{flip-images}

This is an effective way of augmenting data in the opposite direction.
Also, improves model generalization.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}9}]:} \PY{k}{def} \PY{n+nf}{flip}\PY{p}{(}\PY{n}{img}\PY{p}{)}\PY{p}{:}
            \PY{k}{return} \PY{n}{cv2}\PY{o}{.}\PY{n}{flip}\PY{p}{(}\PY{n}{img}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
        
        \PY{n}{test\PYZus{}image\PYZus{}flip} \PY{o}{=} \PY{n}{flip}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}brighten}\PY{p}{)}
        \PY{n}{plt}\PY{o}{.}\PY{n}{imshow}\PY{p}{(}\PY{n}{test\PYZus{}image\PYZus{}flip}\PY{p}{)}
\end{Verbatim}


\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}9}]:} <matplotlib.image.AxesImage at 0x2245f3877b8>
\end{Verbatim}
            
    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_18_1.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Load Images with
Augmentation}\label{load-images-with-augmentation}

For the sake of minimizing computational overhead, all images go through
the following pipeline: 1. Read in the data using cv2.imread() -\/-
size: 160x320x3 2. Crop top/bottom sections of image -\/- size: 75x320x3
3. Resize the image to save on memory -\/- size: 64x64x3 4. Conver to
RGB -\/- size: 64x64x3 5. Blur image -\/- size:64x64x3

For each frame in the logged data, we also have a left/right image which
is slightly off center. We can use these off-center images to
effectively generalize our learning model better. But for now, I'll rely
on the center image data to see how well the steering data is
distributed first. Later, I'll fill in the gaps (imbalances in data
preference to turn right/left) using the left/right image data.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}10}]:} \PY{n}{center\PYZus{}images}\PY{p}{,}\PY{n}{other\PYZus{}images} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{p}{]}
         \PY{n}{center\PYZus{}steering}\PY{p}{,}\PY{n}{other\PYZus{}steering} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{p}{]}
         \PY{n}{time\PYZus{}log} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
         \PY{k}{for} \PY{n}{i}\PY{p}{,}\PY{n}{log} \PY{o+ow}{in} \PY{n+nb}{enumerate}\PY{p}{(}\PY{n}{log\PYZus{}list}\PY{p}{)}\PY{p}{:}
             \PY{k}{if} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{l+m+mi}{1000} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lines\PYZus{}processed: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, lines\PYZus{}left: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, n\PYZus{}center\PYZus{}images\PYZus{}collected: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, time\PYZus{}elapsed\PYZus{}since\PYZus{}last\PYZus{}step: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{i}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{log\PYZus{}list}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{i}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{center\PYZus{}images}\PY{p}{)}\PY{p}{,}\PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{time\PYZus{}log}\PY{p}{)}\PY{p}{)}
                 \PY{n}{time\PYZus{}log} \PY{o}{=} \PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}
             \PY{k}{if} \PY{n}{i} \PY{o}{\PYZpc{}} \PY{l+m+mi}{50} \PY{o}{==} \PY{l+m+mi}{0}\PY{p}{:}
                 \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZhy{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{end}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         
             \PY{n}{center\PYZus{}image\PYZus{}path} \PY{o}{=} \PY{n}{folder\PYZus{}path} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IMG/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{log}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{path\PYZus{}split}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{left\PYZus{}image\PYZus{}path} \PY{o}{=} \PY{n}{folder\PYZus{}path} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IMG/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{log}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{path\PYZus{}split}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
             \PY{n}{right\PYZus{}image\PYZus{}path} \PY{o}{=} \PY{n}{folder\PYZus{}path} \PY{o}{+} \PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{IMG/}\PY{l+s+s1}{\PYZsq{}} \PY{o}{+} \PY{n}{log}\PY{p}{[}\PY{l+m+mi}{0}\PY{p}{]}\PY{o}{.}\PY{n}{split}\PY{p}{(}\PY{n}{path\PYZus{}split}\PY{p}{)}\PY{p}{[}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{p}{]}
             
             \PY{n}{center\PYZus{}image} \PY{o}{=} \PY{n}{blur}\PY{p}{(}\PY{n}{bgr\PYZus{}to\PYZus{}rgb}\PY{p}{(}\PY{n}{resize}\PY{p}{(}\PY{n}{crop}\PY{p}{(}\PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{center\PYZus{}image\PYZus{}path}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{left\PYZus{}image} \PY{o}{=} \PY{n}{blur}\PY{p}{(}\PY{n}{bgr\PYZus{}to\PYZus{}rgb}\PY{p}{(}\PY{n}{resize}\PY{p}{(}\PY{n}{crop}\PY{p}{(}\PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{left\PYZus{}image\PYZus{}path}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             \PY{n}{right\PYZus{}image} \PY{o}{=} \PY{n}{blur}\PY{p}{(}\PY{n}{bgr\PYZus{}to\PYZus{}rgb}\PY{p}{(}\PY{n}{resize}\PY{p}{(}\PY{n}{crop}\PY{p}{(}\PY{n}{cv2}\PY{o}{.}\PY{n}{imread}\PY{p}{(}\PY{n}{right\PYZus{}image\PYZus{}path}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}\PY{p}{)}
             
             \PY{c+c1}{\PYZsh{} record input commands}
             \PY{n}{steering}\PY{p}{,}\PY{n}{thrust}\PY{p}{,}\PY{n}{brake} \PY{o}{=} \PY{n+nb}{float}\PY{p}{(}\PY{n}{log}\PY{p}{[}\PY{l+m+mi}{3}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n+nb}{float}\PY{p}{(}\PY{n}{log}\PY{p}{[}\PY{l+m+mi}{4}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{n+nb}{float}\PY{p}{(}\PY{n}{log}\PY{p}{[}\PY{l+m+mi}{5}\PY{p}{]}\PY{p}{)}
         
             \PY{n}{correction} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.20}\PY{p}{,}\PY{l+m+mf}{0.30}\PY{p}{)}
         
             \PY{n}{center\PYZus{}images}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{center\PYZus{}image}\PY{p}{)}
             \PY{n}{center\PYZus{}steering}\PY{o}{.}\PY{n}{append}\PY{p}{(}\PY{n}{steering}\PY{p}{)}
             \PY{n}{other\PYZus{}images}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{p}{[}\PY{n}{left\PYZus{}image}\PY{p}{,}\PY{n}{right\PYZus{}image}\PY{p}{]}\PY{p}{)}
             \PY{n}{other\PYZus{}steering}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{p}{[}\PY{n}{steering}\PY{o}{+}\PY{n}{correction}\PY{p}{,}\PY{n}{steering}\PY{o}{\PYZhy{}}\PY{n}{correction}\PY{p}{]}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} convert lists to numpy arrays}
         \PY{n}{X\PYZus{}center}\PY{p}{,}\PY{n}{y\PYZus{}center} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{center\PYZus{}images}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{center\PYZus{}steering}\PY{p}{)}
         \PY{n}{X\PYZus{}other}\PY{p}{,}\PY{n}{y\PYZus{}other} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{other\PYZus{}images}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{other\PYZus{}steering}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{lines\PYZus{}processed: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, lines\PYZus{}left: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, n\PYZus{}center\PYZus{}images\PYZus{}collected: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, time\PYZus{}elapsed\PYZus{}since\PYZus{}last\PYZus{}step: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{i}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{log\PYZus{}list}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{i}\PY{p}{,}\PY{n+nb}{len}\PY{p}{(}\PY{n}{center\PYZus{}images}\PY{p}{)}\PY{p}{,}\PY{n}{time}\PY{o}{.}\PY{n}{time}\PY{p}{(}\PY{p}{)}\PY{o}{\PYZhy{}}\PY{n}{time\PYZus{}log}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}center shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}center shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{; X\PYZus{}other shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}other shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}center}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}center}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{X\PYZus{}other}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}other}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]

lines\_processed: 0, lines\_left: 18237, n\_center\_images\_collected: 0, time\_elapsed\_since\_last\_step: 0.0000
--------------------
lines\_processed: 1000, lines\_left: 17237, n\_center\_images\_collected: 1000, time\_elapsed\_since\_last\_step: 4.6096
--------------------
lines\_processed: 2000, lines\_left: 16237, n\_center\_images\_collected: 2000, time\_elapsed\_since\_last\_step: 4.5217
--------------------
lines\_processed: 3000, lines\_left: 15237, n\_center\_images\_collected: 3000, time\_elapsed\_since\_last\_step: 4.5355
--------------------
lines\_processed: 4000, lines\_left: 14237, n\_center\_images\_collected: 4000, time\_elapsed\_since\_last\_step: 4.5092
--------------------
lines\_processed: 5000, lines\_left: 13237, n\_center\_images\_collected: 5000, time\_elapsed\_since\_last\_step: 4.5910
--------------------
lines\_processed: 6000, lines\_left: 12237, n\_center\_images\_collected: 6000, time\_elapsed\_since\_last\_step: 4.5131
--------------------
lines\_processed: 7000, lines\_left: 11237, n\_center\_images\_collected: 7000, time\_elapsed\_since\_last\_step: 4.5427
--------------------
lines\_processed: 8000, lines\_left: 10237, n\_center\_images\_collected: 8000, time\_elapsed\_since\_last\_step: 4.6389
--------------------
lines\_processed: 9000, lines\_left: 9237, n\_center\_images\_collected: 9000, time\_elapsed\_since\_last\_step: 4.5420
--------------------
lines\_processed: 10000, lines\_left: 8237, n\_center\_images\_collected: 10000, time\_elapsed\_since\_last\_step: 4.5385
--------------------
lines\_processed: 11000, lines\_left: 7237, n\_center\_images\_collected: 11000, time\_elapsed\_since\_last\_step: 4.4530
--------------------
lines\_processed: 12000, lines\_left: 6237, n\_center\_images\_collected: 12000, time\_elapsed\_since\_last\_step: 4.5025
--------------------
lines\_processed: 13000, lines\_left: 5237, n\_center\_images\_collected: 13000, time\_elapsed\_since\_last\_step: 4.5578
--------------------
lines\_processed: 14000, lines\_left: 4237, n\_center\_images\_collected: 14000, time\_elapsed\_since\_last\_step: 4.4865
--------------------
lines\_processed: 15000, lines\_left: 3237, n\_center\_images\_collected: 15000, time\_elapsed\_since\_last\_step: 4.5623
--------------------
lines\_processed: 16000, lines\_left: 2237, n\_center\_images\_collected: 16000, time\_elapsed\_since\_last\_step: 4.4914
--------------------
lines\_processed: 17000, lines\_left: 1237, n\_center\_images\_collected: 17000, time\_elapsed\_since\_last\_step: 4.4804
--------------------
lines\_processed: 18000, lines\_left: 237, n\_center\_images\_collected: 18000, time\_elapsed\_since\_last\_step: 4.5255
-----
lines\_processed: 18236, lines\_left: 1, n\_center\_images\_collected: 18237, time\_elapsed\_since\_last\_step: 1.4002
X\_center shape: (18237, 64, 64, 3), y\_center shape: (18237,); X\_other shape: (36474, 64, 64, 3), y\_other shape: (36474,)

    \end{Verbatim}

    \subsubsection{Steering Data Distribution Prior to
Balancing}\label{steering-data-distribution-prior-to-balancing}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}11}]:} \PY{n}{n\PYZus{}bins} \PY{o}{=} \PY{l+m+mi}{30}
         \PY{n}{y\PYZus{}freq}\PY{p}{,} \PY{n}{y\PYZus{}bins}\PY{p}{,} \PY{n}{ignored} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{y\PYZus{}center}\PY{p}{,}\PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bins}\PY{o}{=}\PY{n}{n\PYZus{}bins}\PY{p}{,}\PY{n}{rwidth}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Steering Data Distribution [BEFORE BALANCING]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_22_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Clearly there's an disproportionate amount of data for values that fall
within the 0 (+-0.10) range. This skew creates a bias in the vehicles
steering, which translates to poor performance when it comes to turning
around curves on the track. Thus, it might be beneficial to be more
selective in our training data and attempt to maintain a more uniform
distribution across the various ranges of steering data. This
preprocessing step would allow our model to generalize much better
allowing it to become much more responsive to curves in the track.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}12}]:} \PY{n}{offset} \PY{o}{=} \PY{l+m+mf}{0.17}
         \PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}left\PYZus{}index} \PY{o}{=} \PY{n}{y\PYZus{}center} \PY{o}{\PYZlt{}} \PY{o}{\PYZhy{}}\PY{n}{offset} \PY{c+c1}{\PYZsh{} turning left}
         \PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}center\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}center} \PY{o}{\PYZgt{}} \PY{o}{\PYZhy{}}\PY{n}{offset}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{y\PYZus{}center} \PY{o}{\PYZlt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} mostly central}
         \PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}right\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}center} \PY{o}{\PYZgt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} turning right}
         
         \PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}left\PYZus{}index} \PY{o}{=} \PY{n}{y\PYZus{}other} \PY{o}{\PYZlt{}} \PY{o}{\PYZhy{}}\PY{n}{offset} \PY{c+c1}{\PYZsh{} turning left}
         \PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}center\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}other} \PY{o}{\PYZgt{}} \PY{o}{\PYZhy{}}\PY{n}{offset}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{y\PYZus{}other} \PY{o}{\PYZlt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} mostly central}
         \PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}right\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}other} \PY{o}{\PYZgt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} turning right}
         
         \PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}left\PYZus{}index}\PY{p}{)}\PY{p}{,}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}center\PYZus{}index}\PY{p}{)}\PY{p}{,}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}center\PYZus{}steer\PYZus{}right\PYZus{}index}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[BEFORE BALANCING]: left steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, center steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, right steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[BEFORE BALANCING]: X\PYZus{}data shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}data shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}mean: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}std: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}center}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}center}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y\PYZus{}center}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{y\PYZus{}center}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[BEFORE BALANCING]: left steering: 3619, center steering: 11918, right steering: 2700
[BEFORE BALANCING]: X\_data shape: (18237, 64, 64, 3), y\_data shape: (18237,), y\_mean: -0.0114, y\_std: 0.2715

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}13}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count}\PY{p}{]}\PY{p}{,}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Steering Orientation [BEFORE BALANCING]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_25_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Balancing Steering Data}\label{balancing-steering-data}

A well balanced training data is essential to training a ML model
because the bias apparent in the data will ultimately have an impact on
the performance of the model. Thus, if we have more image data for the
car turning left (becuse the track is traversed in a counter-clockwise
direction), then the training model will also have a preference to the
left. This unbalance in the data will result in the car pulling more to
the left.

Therefore, I determined the general orientation of the dataset and
filled in the gaps by using data that was acquired from the left/right
camera images.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}14}]:} \PY{c+c1}{\PYZsh{} calculate count difference between left/center data, and right/center data}
         \PY{n}{diff\PYZus{}left} \PY{o}{=} \PY{n}{y\PYZus{}center\PYZus{}count} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}left\PYZus{}count}
         \PY{n}{diff\PYZus{}right} \PY{o}{=} \PY{n}{y\PYZus{}center\PYZus{}count} \PY{o}{\PYZhy{}} \PY{n}{y\PYZus{}right\PYZus{}count}
         
         \PY{c+c1}{\PYZsh{} all data is consolidated into these two lists}
         \PY{n}{X\PYZus{}data\PYZus{}list}\PY{p}{,}\PY{n}{y\PYZus{}data\PYZus{}list} \PY{o}{=} \PY{p}{[}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{p}{]}
         
         \PY{c+c1}{\PYZsh{} extend original center image/steering data}
         \PY{n}{X\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{X\PYZus{}center}\PY{p}{)}
         \PY{n}{y\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{y\PYZus{}center}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} add left/right image/steering data to balance out the data bias}
         \PY{n}{X\PYZus{}data\PYZus{}add\PYZus{}right}\PY{p}{,}\PY{n}{y\PYZus{}data\PYZus{}add\PYZus{}right} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{X\PYZus{}other}\PY{p}{[}\PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}right\PYZus{}index}\PY{p}{]}\PY{p}{,}\PY{n}{y\PYZus{}other}\PY{p}{[}\PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}right\PYZus{}index}\PY{p}{]}\PY{p}{,}\PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n}{diff\PYZus{}right}\PY{p}{)}
         \PY{n}{X\PYZus{}data\PYZus{}add\PYZus{}left}\PY{p}{,}\PY{n}{y\PYZus{}data\PYZus{}add\PYZus{}left} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{X\PYZus{}other}\PY{p}{[}\PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}left\PYZus{}index}\PY{p}{]}\PY{p}{,}\PY{n}{y\PYZus{}other}\PY{p}{[}\PY{n}{y\PYZus{}other\PYZus{}steer\PYZus{}left\PYZus{}index}\PY{p}{]}\PY{p}{,}\PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{n}{diff\PYZus{}left}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} extend additional image/steering data}
         \PY{n}{X\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{X\PYZus{}data\PYZus{}add\PYZus{}right}\PY{p}{)}
         \PY{n}{y\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{y\PYZus{}data\PYZus{}add\PYZus{}right}\PY{p}{)}
         \PY{n}{X\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{X\PYZus{}data\PYZus{}add\PYZus{}left}\PY{p}{)}
         \PY{n}{y\PYZus{}data\PYZus{}list}\PY{o}{.}\PY{n}{extend}\PY{p}{(}\PY{n}{y\PYZus{}data\PYZus{}add\PYZus{}left}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} convert lists into a numpy array}
         \PY{n}{X\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{X\PYZus{}data\PYZus{}list}\PY{p}{)}
         \PY{n}{y\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{array}\PY{p}{(}\PY{n}{y\PYZus{}data\PYZus{}list}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} save fully processed and balanced X and y data to local disk}
         \PY{n}{np}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{X\PYZus{}data}\PY{p}{)}
         \PY{n}{np}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}data}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{y\PYZus{}data}\PY{p}{)}
\end{Verbatim}


    \subsubsection{Before and After Comparison of Steering Angle
Balancing}\label{before-and-after-comparison-of-steering-angle-balancing}

The steering data prior to balancing to after: * BEFORE: y\_mean:
-0.0114, y\_std: 0.2715 * AFTER: y\_mean: 0.0016, y\_std: 0.3402

Prior to balancing our data, the data had a 0.0114 degree preference to
the left and a narrow variance of 0.2715. To balance out the angle of
the steering data in the model, I used the left/right images to fill the
gap (difference from center count to left/right count).

After we applied the balancing step, the y\_mean (steering angle) is
much closer to 0, indicating a more even distribution of the steering
angle data. In addition, the variance appears to be slightly larger as
well. A higher variance is desirable in this case because this allows
the model to be well-rounded, rather than having a preference to any
given angle.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}15}]:} \PY{n}{y\PYZus{}steer\PYZus{}left\PYZus{}index} \PY{o}{=} \PY{n}{y\PYZus{}data} \PY{o}{\PYZlt{}} \PY{o}{\PYZhy{}}\PY{n}{offset} \PY{c+c1}{\PYZsh{} turning left}
         \PY{n}{y\PYZus{}steer\PYZus{}center\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}data} \PY{o}{\PYZgt{}} \PY{o}{\PYZhy{}}\PY{n}{offset}\PY{p}{)} \PY{o}{\PYZam{}} \PY{p}{(}\PY{n}{y\PYZus{}data} \PY{o}{\PYZlt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} mostly central}
         \PY{n}{y\PYZus{}steer\PYZus{}right\PYZus{}index} \PY{o}{=} \PY{p}{(}\PY{n}{y\PYZus{}data} \PY{o}{\PYZgt{}} \PY{n}{offset}\PY{p}{)} \PY{c+c1}{\PYZsh{} turning right}
         
         \PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count} \PY{o}{=} \PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}steer\PYZus{}left\PYZus{}index}\PY{p}{)}\PY{p}{,}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}steer\PYZus{}center\PYZus{}index}\PY{p}{)}\PY{p}{,}\PY{n+nb}{sum}\PY{p}{(}\PY{n}{y\PYZus{}steer\PYZus{}right\PYZus{}index}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[AFTER BALANCING]: left steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, center steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, right steering: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[AFTER BALANCING]: X\PYZus{}data shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}data shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}mean: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}std: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}data}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y\PYZus{}data}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{y\PYZus{}data}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[AFTER BALANCING]: left steering: 11918, center steering: 11918, right steering: 11918
[AFTER BALANCING]: X\_data shape: (35754, 64, 64, 3), y\_data shape: (35754,), y\_mean: 0.0016, y\_std: 0.3402

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}16}]:} \PY{n}{plt}\PY{o}{.}\PY{n}{bar}\PY{p}{(}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{left}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{center}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{right}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{,}\PY{p}{[}\PY{n}{y\PYZus{}left\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}center\PYZus{}count}\PY{p}{,}\PY{n}{y\PYZus{}right\PYZus{}count}\PY{p}{]}\PY{p}{,}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Steering Orientation [AFTER BALANCING]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_30_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    Although the general steering orientation appears to have leveled out
and the mean has converged closer to zero, the histogram tells us a
slightly different story. The histogram is a lot more balanced then it
was before, however, it's not perfectly symmetrical. We'll focus on this
in the next section.

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}17}]:} \PY{n}{freq}\PY{p}{,}\PY{n}{bins}\PY{p}{,}\PY{n}{\PYZus{}} \PY{o}{=} \PY{n}{plt}\PY{o}{.}\PY{n}{hist}\PY{p}{(}\PY{n}{y\PYZus{}data}\PY{p}{,}\PY{n}{color}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{r}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,}\PY{n}{bins}\PY{o}{=}\PY{n}{n\PYZus{}bins}\PY{o}{*}\PY{l+m+mi}{2}\PY{p}{,}\PY{n}{rwidth}\PY{o}{=}\PY{l+m+mf}{0.8}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{title}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{Steering Data Distribution [AFTER BALANCING]}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{plt}\PY{o}{.}\PY{n}{show}\PY{p}{(}\PY{p}{)}
\end{Verbatim}


    \begin{center}
    \adjustimage{max size={0.9\linewidth}{0.9\paperheight}}{output_32_0.png}
    \end{center}
    { \hspace*{\fill} \\}
    
    \subsubsection{Load Data, Shuffle, and Split for
Training/Validation}\label{load-data-shuffle-and-split-for-trainingvalidation}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}18}]:} \PY{c+c1}{\PYZsh{} load X \PYZam{} y data and shuffle}
         \PY{n}{X\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{X\PYZus{}data.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{y\PYZus{}data} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{load}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{y\PYZus{}data.npy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
         \PY{n}{X\PYZus{}data}\PY{p}{,}\PY{n}{y\PYZus{}data} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{,}\PY{n}{y\PYZus{}data}\PY{p}{,}\PY{n}{n\PYZus{}samples}\PY{o}{=}\PY{l+m+mi}{10000}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} split the data up for training/testing}
         \PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{X\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}valid} \PY{o}{=} \PY{n}{train\PYZus{}test\PYZus{}split}\PY{p}{(}\PY{n}{X\PYZus{}data}\PY{p}{,} \PY{n}{y\PYZus{}data}\PY{p}{,} \PY{n}{test\PYZus{}size} \PY{o}{=} \PY{l+m+mf}{0.20}\PY{p}{,} \PY{n}{random\PYZus{}state} \PY{o}{=} \PY{l+m+mi}{42}\PY{p}{)}
         
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[TRAINING AND VALIDATION DATA]: X\PYZus{}train shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}train shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, X\PYZus{}valid shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}valid shape: }\PY{l+s+si}{\PYZob{}\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{X\PYZus{}valid}\PY{o}{.}\PY{n}{shape}\PY{p}{,}\PY{n}{y\PYZus{}valid}\PY{o}{.}\PY{n}{shape}\PY{p}{)}\PY{p}{)}
         \PY{n+nb}{print}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{[TRAINING AND VALIDATION DATA]: y\PYZus{}train mean: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}train std: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}valid mean: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{, y\PYZus{}valid std: }\PY{l+s+si}{\PYZob{}:.4f\PYZcb{}}\PY{l+s+s1}{\PYZsq{}}\PY{o}{.}\PY{n}{format}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{y\PYZus{}train}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{mean}\PY{p}{(}\PY{n}{y\PYZus{}valid}\PY{p}{)}\PY{p}{,}\PY{n}{np}\PY{o}{.}\PY{n}{std}\PY{p}{(}\PY{n}{y\PYZus{}valid}\PY{p}{)}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
[TRAINING AND VALIDATION DATA]: X\_train shape: (8000, 64, 64, 3), y\_train shape: (8000,), X\_valid shape: (2000, 64, 64, 3), y\_valid shape: (2000,)
[TRAINING AND VALIDATION DATA]: y\_train mean: 0.0025, y\_train std: 0.3353, y\_valid mean: -0.0080, y\_valid std: 0.3442

    \end{Verbatim}

    \subsubsection{Generators}\label{generators}

These generator functions were developed to minimize the memory load on
the GPU. In addition, the generator helps to generalize the model by
applying the following steps: * Brightness adjustment to all batch
images using the random\_brightness() method * Slight angle variation to
all steering angles (90\%-110\% of original steering angle) * Flip batch
images and steering angles horizontally (only applied to 50\% of the
batch images)

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}19}]:} \PY{c+c1}{\PYZsh{} model generators used to minimize memory usage when training model}
         \PY{k}{def} \PY{n+nf}{train\PYZus{}generator}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
             \PY{n}{X\PYZus{}batch} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{dtype} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
             \PY{n}{y\PYZus{}batch} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,}\PY{p}{)}\PY{p}{,} \PY{n}{dtype} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
             \PY{n}{X\PYZus{}shuffled}\PY{p}{,} \PY{n}{y\PYZus{}shuffled} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
             \PY{k}{while} \PY{k+kc}{True}\PY{p}{:}
                 \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                     \PY{n}{rand} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}shuffled}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                     \PY{n}{X\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{random\PYZus{}brightness}\PY{p}{(}\PY{n}{X\PYZus{}shuffled}\PY{p}{[}\PY{n}{rand}\PY{p}{]}\PY{p}{)}
                     \PY{n}{y\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}shuffled}\PY{p}{[}\PY{n}{rand}\PY{p}{]}\PY{o}{*}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{uniform}\PY{p}{(}\PY{l+m+mf}{0.90}\PY{p}{,}\PY{l+m+mf}{1.10}\PY{p}{)}
         
                     \PY{n}{coin} \PY{o}{=} \PY{n}{random}\PY{o}{.}\PY{n}{randint}\PY{p}{(}\PY{l+m+mi}{0}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}
                     \PY{k}{if} \PY{n}{coin} \PY{o}{==} \PY{l+m+mi}{1}\PY{p}{:}
                         \PY{n}{X\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{,} \PY{n}{y\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{flip}\PY{p}{(}\PY{n}{X\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]}\PY{p}{)}\PY{p}{,}\PY{o}{\PYZhy{}}\PY{l+m+mi}{1}\PY{o}{*}\PY{n}{y\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]}
         
                 \PY{k}{yield} \PY{n}{X\PYZus{}batch}\PY{p}{,} \PY{n}{y\PYZus{}batch}
         
         \PY{c+c1}{\PYZsh{} model generators used to minimize memory usage when training model}
         \PY{k}{def} \PY{n+nf}{valid\PYZus{}generator}\PY{p}{(}\PY{n}{X}\PY{p}{,}\PY{n}{y}\PY{p}{,}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
             \PY{n}{X\PYZus{}batch} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{)}\PY{p}{,} \PY{n}{dtype} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
             \PY{n}{y\PYZus{}batch} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{zeros}\PY{p}{(}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{,}\PY{p}{)}\PY{p}{,} \PY{n}{dtype} \PY{o}{=} \PY{n}{np}\PY{o}{.}\PY{n}{float32}\PY{p}{)}
             \PY{n}{X\PYZus{}shuffled}\PY{p}{,} \PY{n}{y\PYZus{}shuffled} \PY{o}{=} \PY{n}{shuffle}\PY{p}{(}\PY{n}{X}\PY{p}{,} \PY{n}{y}\PY{p}{)}
             \PY{k}{while} \PY{k+kc}{True}\PY{p}{:}
                 \PY{k}{for} \PY{n}{i} \PY{o+ow}{in} \PY{n+nb}{range}\PY{p}{(}\PY{n}{batch\PYZus{}size}\PY{p}{)}\PY{p}{:}
                     \PY{n}{rand} \PY{o}{=} \PY{n+nb}{int}\PY{p}{(}\PY{n}{np}\PY{o}{.}\PY{n}{random}\PY{o}{.}\PY{n}{choice}\PY{p}{(}\PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}shuffled}\PY{p}{)}\PY{p}{,}\PY{l+m+mi}{1}\PY{p}{)}\PY{p}{)}
                     \PY{n}{X\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{X\PYZus{}shuffled}\PY{p}{[}\PY{n}{rand}\PY{p}{]}
                     \PY{n}{y\PYZus{}batch}\PY{p}{[}\PY{n}{i}\PY{p}{]} \PY{o}{=} \PY{n}{y\PYZus{}shuffled}\PY{p}{[}\PY{n}{rand}\PY{p}{]}
         
                 \PY{k}{yield} \PY{n}{X\PYZus{}batch}\PY{p}{,} \PY{n}{y\PYZus{}batch}
\end{Verbatim}


    \subsubsection{Hyperparameters and Model
Pipeline}\label{hyperparameters-and-model-pipeline}

The following hyper-parameters were selected for our model: *
BATCH\_SIZE = 128 * EPOCHS = 5 * LR = 0.001

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}20}]:} \PY{c+c1}{\PYZsh{} model hyperparameters}
         \PY{n}{BATCH\PYZus{}SIZE} \PY{o}{=} \PY{l+m+mi}{128}
         \PY{n}{EPOCHS} \PY{o}{=} \PY{l+m+mi}{3}
         \PY{n}{LR} \PY{o}{=} \PY{l+m+mf}{0.001}
         
         \PY{c+c1}{\PYZsh{} initialize generators}
         \PY{n}{train\PYZus{}gen} \PY{o}{=} \PY{n}{train\PYZus{}generator}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{,} \PY{n}{y\PYZus{}train}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{p}{)}
         \PY{n}{valid\PYZus{}gen} \PY{o}{=} \PY{n}{valid\PYZus{}generator}\PY{p}{(}\PY{n}{X\PYZus{}valid}\PY{p}{,} \PY{n}{y\PYZus{}valid}\PY{p}{,} \PY{n}{BATCH\PYZus{}SIZE}\PY{p}{)}
         
         \PY{c+c1}{\PYZsh{} NVIDIA INSPIRED NETWORK ARCHITECTURE}
         \PY{n}{model} \PY{o}{=} \PY{n}{Sequential}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Lambda}\PY{p}{(}\PY{k}{lambda} \PY{n}{x}\PY{p}{:} \PY{p}{(}\PY{n}{x}\PY{o}{/}\PY{l+m+mi}{255}\PY{p}{)} \PY{o}{\PYZhy{}} \PY{l+m+mf}{0.5}\PY{p}{,}\PY{n}{input\PYZus{}shape}\PY{o}{=}\PY{n}{X\PYZus{}train}\PY{o}{.}\PY{n}{shape}\PY{p}{[}\PY{l+m+mi}{1}\PY{p}{:}\PY{p}{]}\PY{p}{)}\PY{p}{)} \PY{c+c1}{\PYZsh{} normalization layer}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Convolution2D}\PY{p}{(}\PY{l+m+mi}{24}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{n}{border\PYZus{}mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{valid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Convolution2D}\PY{p}{(}\PY{l+m+mi}{36}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{n}{border\PYZus{}mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{valid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Convolution2D}\PY{p}{(}\PY{l+m+mi}{48}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{l+m+mi}{5}\PY{p}{,} \PY{n}{border\PYZus{}mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{valid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Convolution2D}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{n}{border\PYZus{}mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{same}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Convolution2D}\PY{p}{(}\PY{l+m+mi}{64}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{l+m+mi}{3}\PY{p}{,} \PY{n}{border\PYZus{}mode}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{valid}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{subsample}\PY{o}{=}\PY{p}{(}\PY{l+m+mi}{2}\PY{p}{,}\PY{l+m+mi}{2}\PY{p}{)}\PY{p}{,} \PY{n}{activation}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{relu}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Flatten}\PY{p}{(}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{80}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{40}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{20}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dropout}\PY{p}{(}\PY{l+m+mf}{0.5}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{10}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{add}\PY{p}{(}\PY{n}{Dense}\PY{p}{(}\PY{l+m+mi}{1}\PY{p}{,} \PY{n}{W\PYZus{}regularizer} \PY{o}{=} \PY{n}{l2}\PY{p}{(}\PY{n}{LR}\PY{p}{)}\PY{p}{)}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{compile}\PY{p}{(}\PY{n}{optimizer}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{adam}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{loss}\PY{o}{=}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{mse}\PY{l+s+s1}{\PYZsq{}}\PY{p}{,} \PY{n}{metrics}\PY{o}{=}\PY{p}{[}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{accuracy}\PY{l+s+s1}{\PYZsq{}}\PY{p}{]}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{summary}\PY{p}{(}\PY{p}{)}
         \PY{n}{model}\PY{o}{.}\PY{n}{fit\PYZus{}generator}\PY{p}{(}\PY{n}{train\PYZus{}gen}\PY{p}{,} \PY{n}{samples\PYZus{}per\PYZus{}epoch} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}train}\PY{p}{)}\PY{p}{,} \PY{n}{epochs}\PY{o}{=}\PY{n}{EPOCHS}\PY{p}{,} \PY{n}{validation\PYZus{}data}\PY{o}{=}\PY{n}{valid\PYZus{}gen}\PY{p}{,} \PY{n}{nb\PYZus{}val\PYZus{}samples} \PY{o}{=} \PY{n+nb}{len}\PY{p}{(}\PY{n}{X\PYZus{}valid}\PY{p}{)}\PY{p}{)}
\end{Verbatim}


    \begin{Verbatim}[commandchars=\\\{\}]
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:13: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(24, (5, 5), kernel\_regularizer=<keras.reg{\ldots}, activation="relu", strides=(2, 2), padding="valid")`
  del sys.path[0]
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:14: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(36, (5, 5), kernel\_regularizer=<keras.reg{\ldots}, activation="relu", strides=(2, 2), padding="valid")`
  
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(48, (5, 5), kernel\_regularizer=<keras.reg{\ldots}, activation="relu", strides=(2, 2), padding="valid")`
  from ipykernel import kernelapp as app
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:16: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel\_regularizer=<keras.reg{\ldots}, activation="relu", strides=(2, 2), padding="same")`
  app.launch\_new\_instance()
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:17: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), kernel\_regularizer=<keras.reg{\ldots}, activation="relu", strides=(2, 2), padding="valid")`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(80, kernel\_regularizer=<keras.reg{\ldots})`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:21: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(40, kernel\_regularizer=<keras.reg{\ldots})`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:23: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(20, kernel\_regularizer=<keras.reg{\ldots})`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:25: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(10, kernel\_regularizer=<keras.reg{\ldots})`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:26: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel\_regularizer=<keras.reg{\ldots})`
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:29: UserWarning: The semantics of the Keras 2 argument `steps\_per\_epoch` is not the same as the Keras 1 argument `samples\_per\_epoch`. `steps\_per\_epoch` is the number of batches to draw from the generator at each epoch. Basically steps\_per\_epoch = samples\_per\_epoch/batch\_size. Similarly `nb\_val\_samples`->`validation\_steps` and `val\_samples`->`steps` arguments have changed. Update your method calls accordingly.
C:\textbackslash{}Users\textbackslash{}Selim\textbackslash{}Anaconda3\textbackslash{}envs\textbackslash{}tfenv\textbackslash{}lib\textbackslash{}site-packages\textbackslash{}ipykernel\_launcher.py:29: UserWarning: Update your `fit\_generator` call to the Keras 2 API: `fit\_generator(<generator{\ldots}, epochs=3, validation\_data=<generator{\ldots}, validation\_steps=2000, steps\_per\_epoch=8000)`

    \end{Verbatim}

    \begin{Verbatim}[commandchars=\\\{\}]
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Layer (type)                 Output Shape              Param \#   
=================================================================
lambda\_1 (Lambda)            (None, 64, 64, 3)         0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv2d\_1 (Conv2D)            (None, 30, 30, 24)        1824      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv2d\_2 (Conv2D)            (None, 13, 13, 36)        21636     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv2d\_3 (Conv2D)            (None, 5, 5, 48)          43248     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv2d\_4 (Conv2D)            (None, 3, 3, 64)          27712     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
conv2d\_5 (Conv2D)            (None, 1, 1, 64)          36928     
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
flatten\_1 (Flatten)          (None, 64)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_1 (Dense)              (None, 80)                5200      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_1 (Dropout)          (None, 80)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_2 (Dense)              (None, 40)                3240      
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_2 (Dropout)          (None, 40)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_3 (Dense)              (None, 20)                820       
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dropout\_3 (Dropout)          (None, 20)                0         
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_4 (Dense)              (None, 10)                210       
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
dense\_5 (Dense)              (None, 1)                 11        
=================================================================
Total params: 140,829
Trainable params: 140,829
Non-trainable params: 0
\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_\_
Epoch 1/3
8000/8000 [==============================] - 309s 39ms/step - loss: 0.1157 - acc: 0.2185 - val\_loss: 0.1181 - val\_acc: 0.2130
Epoch 2/3
8000/8000 [==============================] - 203s 25ms/step - loss: 0.1133 - acc: 0.2189 - val\_loss: 0.1192 - val\_acc: 0.2134
Epoch 3/3
8000/8000 [==============================] - 200s 25ms/step - loss: 0.1127 - acc: 0.2198 - val\_loss: 0.1180 - val\_acc: 0.2133

    \end{Verbatim}

\begin{Verbatim}[commandchars=\\\{\}]
{\color{outcolor}Out[{\color{outcolor}20}]:} <keras.callbacks.History at 0x2243e07bcf8>
\end{Verbatim}
            
    \subsubsection{Save Trained Models}\label{save-trained-models}

    \begin{Verbatim}[commandchars=\\\{\}]
{\color{incolor}In [{\color{incolor}21}]:} \PY{n}{model}\PY{o}{.}\PY{n}{save}\PY{p}{(}\PY{l+s+s1}{\PYZsq{}}\PY{l+s+s1}{model.h5}\PY{l+s+s1}{\PYZsq{}}\PY{p}{)}
\end{Verbatim}


    \subsection{Training Data}\label{training-data}

For this project, I collected 18,237 frames of training data
(left/center/right images and steering angles). This training dataset
was then rebalanced to ensure that the steering angles were equally
distributed across left/center/right driving orientations. After all was
said and done, I had a training set with 32,000 images and steering
angles.

When training the model, I randomly sampled the large 32,000 training
dataset down to 10,000 before using sklearns train\_test\_split() method
to split the dataset into 80\% training data (8,000) and 20\%
validation/test data (2,000).

\subsection{Approach Summary}\label{approach-summary}

Getting the model to perform smoothly took countless hours of data
collection, training the model, more data collection, tweaking
parameters, then training and re-training to get the architecture just
right. This iterative approach is what ultimately led to my success.

Everytime I implemented a new idea for a slightly modified network
architecture, or a new pre-processing step, I could visibly see how it
had an impact on the performance of the model. I tested, tuned, and
tested some more. During this phase, I learned a number of things about
behavioral learning (and ML in general) that are absolutely critical to
a model's performance. First and foremost, generalization is king. A
model that is able to generalize well, will also perform well, and
vice-versa.

Ok, great. Now that we understand generalization is a critical factor
that's directly correlated with a model's performance, how can we
generalize better when developing a behavioral cloning model for a self
driving car?

\subsubsection{1. Collect lots of data}\label{collect-lots-of-data}

The more you have of it, the better the model can train to handle
variation, and the less likely it is to overfit into a specific path on
the track. I took about 2 loops (counter-clockwise) initially, then also
travelled in a clockwise direction for about 2 laps while remaining in
the center of the road. This proved to be a good starting point but the
model seemed to be overfitting to the small dataset. The model would
perform well while the car remained in the center of the road but as
soon as it offsets, the model doesn't know which direction to go. \#\#\#
2. Collect some more (recovery) data Even-though I had collected a
significant amount of training data, the model was still showing subpar
performance and this was simply because I didn't have enough variation.
My intuitive thought process was that: if I drive a few laps around the
track, while maintaining a smooth and relatively central orientation on
the track, I would expect my model to learn and do the same.

I learned the hard way that this isn't an effective approach, simply
because I didn't provide the learning model with the proper training
data to learn how to recover and center back onto the road in the event
that it goes off-center. Thus, I had to collect training data with a
different driving style. So instead, I tried swaying left to right as I
moved around the track. Providing this training data provided a bigger
learning opportunity for the model as its exposed it to learning how to
react in other scenarios such as drifting too far right/left and how to
recover. \#\#\# 3. Pre-processing is an essential step for all training
data Having lots of training data is important to a model only if its
processed properly. Here are the preprocessing steps that I used in my
training data pipeline: * Analyzing training data distribution and
counter-balancing data offsets (mean further away from zero) with
left/right images to combat training data bias * Reduced memory overhead
by cropping a 160x320x3 image down to 75x320x3, and scaling it down to
64x64x3 * Improved model generalization by randomzing the image
brightness, applying blur and flipping images horizontally

Naturally, this results in a dataset that has a steering bias to the
left. If a model were to be trained on this dataset, it'd inherently
pull more to the left. I combated this phenomenon by balancing the
steering angle distribution using the left/right camera images recorded
during training.

\subsection{Model Architecture and
Hyper-parameters}\label{model-architecture-and-hyper-parameters}

The following hyper-parameters were selected for our model: *
BATCH\_SIZE = 128 * EPOCHS = 5 * LR = 0.001

I applied some transfer learning by initially starting with Nvidia's
Network Architecture that was used to train their own self-driving
vehicles and modifying it slightly. The Nvidia network architecture
looks like this:

For the sake of speeding up the training process and avoiding
limited-memory issues, I retained their 5 convolutional layers, but
reduced the size of their massive fully connected layers. Instead this
is what my modified Nvidia architecture looks like: * Normalization
layer - images with mean 127.5 and range {[}0,255{]}, normalized to mean
0 and range {[}-0.5,0.5{]} * Convolutional layer - 5x5 filter with a
depth of 24 and ReLU activation * Convolutional layer - 5x5 filter with
a depth of 36 and ReLU activation * Convolutional layer - 5x5 filter
with a depth of 48 and ReLU activation * Convolutional layer - 3x3
filter with a depth of 64 and ReLU activation * Convolutional layer -
3x3 filter with a depth of 64 and ReLU activation * Flatten layer *
Fully Connected layer - 80 nodes * Dropout layer (to prevent
overfitting) - 50\% * Fully Connected layer - 40 nodes * Dropout layer
(to prevent overfitting) - 50\% * Fully Connected layer - 16 nodes *
Dropout layer (to prevent overfitting) - 50\% * Fully Connected layer -
10 nodes * Fully Connected layer - 1 node (steering angle output)

The model weights were fully trained from scratch using 8,000 training
data (randomly sampled from a much larger dataset of 32,000) and
validated for accuracy using 2,000 validation image/steering data.
Moreover, an Adam optimizer was used to train the model parameters and
minimize the loss function.

\subsection{Model Performance}\label{model-performance}

Here's a gif of the model in action, replayed back at 400\% the original
speed (click on gif to see video):

As we can see, the model performs quite well. It handles the turns
smoothly while remaining relatively central throughout the entire track.

\subsection{Lessons Learned}\label{lessons-learned}

\begin{itemize}
\tightlist
\item
  It pays to have a powerful GPU - taking an iterative approach to
  developing a model gives you a chance to implement various ideas
  relatively quickly. However, training and re-training new ideas
  becomes much less viable on a CPU (or integrated grahpics on a
  laptop). The same model that would take my GTX 1060 (on my pc) only 10
  minutes to train, would take my macbook pro at least a few hours.
\item
  Collecting "perfect" training data (in this case, driving exactly in
  the middle of the road) doesn't translate to a model that also drives
  perfectly in the middle of the road. A learning model needs data that
  has variance, otherwise it tends to overfit to a specific path along
  the track and performs poorly when it falls slightly off-course.
\item
  Ensure that the collected training dataset is evenly distributed,
  otherwise expect the bias apparent in data to also transfer to the
  model
\item
  Utilize preprocessing steps (cropping + rescaling) to reduce the
  memory overhead of the training data
\item
  Use regularization to minimize the number of weights used by the
  model. Since a self-driving car needs to make decisions almost on the
  fly, minimizing the size of the network model is critical.
\item
  Use generators to minmize the memory overhead
\item
  Quality over quantity. Having lots of training data is good for
  training a model, however, what's really more important is the quality
  of the training data. And by quality, what I really mean is having a
  lot of variation. This variation is essential for teaching a model to
  generalize more effectively. For example:

  \begin{itemize}
  \tightlist
  \item
    A CNN model that learned from \textasciitilde{}10,000 training data
    of me driving perfectly central around the track resulted in
    relatively poor performance
  \item
    However, when I collected more variation in my driving style and
    randomly sampled a 32,000 training dataset to only 2,000 images, it
    performed significantly better than my model that had trained with
    10,000 images.
  \end{itemize}
\end{itemize}

\subsection{Future Plans}\label{future-plans}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Collect additional training data on track 2 and see how the model
  performs using the same pre-processing steps and network architecture.
\item
  I'd like to see if I could get a much smaller network architecture
  (less layers and weights) to perform as well as (or better) than the
  NVIDIA inspired architecture that was used for this project
\item
  Try testing different architectures like VGG/ResNet and comparing
  their performance
\end{enumerate}


    % Add a bibliography block to the postdoc
    
    
    
    \end{document}
